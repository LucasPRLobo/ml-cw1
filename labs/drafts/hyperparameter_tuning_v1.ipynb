{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef652d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.compose import ColumnTransformer                                                                                                                                                           \n",
    "from sklearn.preprocessing import OneHotEncoder                                                                                                                                                         \n",
    "from sklearn.pipeline import Pipeline    \n",
    "\n",
    "# Models                                                                                                                                                                                                \n",
    "from sklearn.ensemble import (                                                                                                                                                                          \n",
    "    GradientBoostingRegressor,                                                                                                                                                                          \n",
    "    HistGradientBoostingRegressor,                                                                                                                                                                      \n",
    "    RandomForestRegressor                                                                                                                                                                               \n",
    ")              \n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "                                                                                                                                                                                                        \n",
    "# Tuning                                                                                                                                                                                                \n",
    "from sklearn.model_selection import (                                                                                                                                                                   \n",
    "    cross_val_score,                                                                                                                                                                                    \n",
    "    KFold,                                                                                                                                                                                              \n",
    "    RandomizedSearchCV,                                                                                                                                                                                 \n",
    "    GridSearchCV                                                                                                                                                                                        \n",
    ")       \n",
    "\n",
    "# Utilities                                                                                                                                                                                             \n",
    "import time                                                                                                                                                                                             \n",
    "import warnings                                                                                                                                                                                         \n",
    "warnings.filterwarnings('ignore')                                                                                                                                                                       \n",
    "                                                                                                                                                                                                        \n",
    "# Random seed                                                                                                                                                                                           \n",
    "RANDOM = 123                                                                                                                                                                                            \n",
    "np.random.seed(RANDOM)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e99c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/CW1_train.csv')\n",
    "X = train.drop(columns=['outcome', 'price', 'x', 'y', 'z'])  # Reduced features                                                                                                                            \n",
    "y = train['outcome']\n",
    "\n",
    "\n",
    "# Feature groups                                                                                                                                                                                        \n",
    "categorical_cols = ['cut', 'color', 'clarity']                                                                                                                                                          \n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]                                                                                                                                \n",
    "                                                                                                                                                                                                        \n",
    "# Preprocessor                                                                                                                                                                                          \n",
    "preprocessor = ColumnTransformer([                                                                                                                                                                      \n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),                                                                                                                        \n",
    "    ('num', 'passthrough', numeric_cols)                                                                                                                                                                \n",
    "])                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                        \n",
    "# CV setup                                                                                                                                                                                              \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM)             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning GradientBoosting...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    " # Define parameter search space                                                                                                                                                                         \n",
    "param_dist_gb = {                                                                                                                                                                                       \n",
    "    'model__n_estimators': [100, 200, 300, 400, 500],                                                                                                                                                   \n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],                                                                                                                                               \n",
    "    'model__max_depth': [3, 4, 5, 6, 7, 8],                                                                                                                                                             \n",
    "    'model__min_samples_split': [2, 5, 10, 20],                                                                                                                                                         \n",
    "    'model__min_samples_leaf': [1, 2, 4, 8],                                                                                                                                                            \n",
    "    'model__subsample': [0.7, 0.8, 0.9, 1.0],                                                                                                                                                           \n",
    "    'model__max_features': ['sqrt', 'log2', 0.5, 0.7, None]                                                                                                                                             \n",
    "}                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                          \n",
    "  # Create pipeline                                                                                                                                                                                       \n",
    "pipe_gb = Pipeline([                                                                                                                                                                                    \n",
    "    ('prep', preprocessor),                                                                                                                                                                             \n",
    "    ('model', GradientBoostingRegressor(random_state=RANDOM))                                                                                                                                           \n",
    "])                                                                                                                                                                                                      \n",
    "                                                                                                                                                                                                          \n",
    "  # Randomized search (100 iterations)                                                                                                                                                                    \n",
    "print(\"Tuning GradientBoosting...\")                                                                                                                                                                     \n",
    "start = time.time()                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                        \n",
    "search_gb = RandomizedSearchCV(                                                                                                                                                                         \n",
    "    pipe_gb,                                                                                                                                                                                            \n",
    "    param_distributions=param_dist_gb,                                                                                                                                                                  \n",
    "    n_iter=100,                                                                                                                                                                                         \n",
    "    cv=cv,                                                                                                                                                                                              \n",
    "    scoring='r2',                                                                                                                                                                                       \n",
    "    n_jobs=-1,                                                                                                                                                                                          \n",
    "    random_state=RANDOM,                                                                                                                                                                                \n",
    "    verbose=1                                                                                                                                                                                           \n",
    ")                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                        \n",
    "search_gb.fit(X, y)                                                                                                                                                                                     \n",
    "elapsed = time.time() - start                                                                                                                                                                           \n",
    "                                                                                                                                                                                                        \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                                                                 \n",
    "print(f\"Best CV R²: {search_gb.best_score_:.4f}\")                                                                                                                                                       \n",
    "print(f\"\\nBest parameters:\")                                                                                                                                                                            \n",
    "for param, value in search_gb.best_params_.items():                                                                                                                                                     \n",
    "    print(f\"  {param}: {value}\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 1296 combinations\n",
      "\n",
      "Refining GradientBoosting...\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "\n",
      "Completed in 4032.8s\n",
      "Best CV R²: 0.4741\n",
      "\n",
      "Best parameters:\n",
      "  model__learning_rate: 0.05\n",
      "  model__max_depth: 2\n",
      "  model__max_features: None\n",
      "  model__min_samples_leaf: 5\n",
      "  model__min_samples_split: 2\n",
      "  model__n_estimators: 300\n",
      "  model__subsample: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Focused grid around best parameters                                                                                                                                                                   \n",
    "param_grid_gb = {                                                                                                                                                                                       \n",
    "    'model__n_estimators': [150, 200, 250, 300],                                                                                                                                                        \n",
    "    'model__learning_rate': [0.03, 0.05, 0.07],                                                                                                                                                         \n",
    "    'model__max_depth': [2, 3, 4],                                                                                                                                                                      \n",
    "    'model__min_samples_split': [2, 3],                                                                                                                                                                 \n",
    "    'model__min_samples_leaf': [3, 4, 5],                                                                                                                                                               \n",
    "    'model__subsample': [0.85, 0.9, 0.95],                                                                                                                                                              \n",
    "    'model__max_features': [None, 0.8]                                                                                                                                                                  \n",
    "}                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                        \n",
    "print(f\"Grid size: {np.prod([len(v) for v in param_grid_gb.values()])} combinations\")                                                                                                                   \n",
    "                                                                                                                                                                                                        \n",
    "# Grid search                                                                                                                                                                                           \n",
    "print(\"\\nRefining GradientBoosting...\")                                                                                                                                                                 \n",
    "start = time.time()                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                        \n",
    "grid_gb = GridSearchCV(                                                                                                                                                                                 \n",
    "    pipe_gb,                                                                                                                                                                                            \n",
    "    param_grid=param_grid_gb,                                                                                                                                                                           \n",
    "    cv=cv,                                                                                                                                                                                              \n",
    "    scoring='r2',                                                                                                                                                                                       \n",
    "    n_jobs=-1,                                                                                                                                                                                          \n",
    "    verbose=1                                                                                                                                                                                           \n",
    ")                                                                                                                                                                                                       \n",
    "                                                                                                                                                                                                        \n",
    "grid_gb.fit(X, y)                                                                                                                                                                                       \n",
    "elapsed = time.time() - start                                                                                                                                                                           \n",
    "                                                                                                                                                                                                        \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                                                                 \n",
    "print(f\"Best CV R²: {grid_gb.best_score_:.4f}\")                                                                                                                                                         \n",
    "print(f\"\\nBest parameters:\")                                                                                                                                                                            \n",
    "for param, value in grid_gb.best_params_.items():                                                                                                                                                       \n",
    "    print(f\"  {param}: {value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning XGBoost...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed in 35.2s\n",
      "Best CV R²: 0.4739\n",
      "\n",
      "Best parameters:\n",
      "  model__subsample: 0.7\n",
      "  model__reg_lambda: 5\n",
      "  model__reg_alpha: 1\n",
      "  model__n_estimators: 400\n",
      "  model__min_child_weight: 1\n",
      "  model__max_depth: 2\n",
      "  model__learning_rate: 0.03\n",
      "  model__colsample_bytree: 0.7\n"
     ]
    }
   ],
   "source": [
    "pipe_xgb = Pipeline([                                                                                                                                   \n",
    "    ('prep', preprocessor),                                                                                                                             \n",
    "    ('model', XGBRegressor(random_state=RANDOM, n_jobs=-1))                                                                                             \n",
    "])                                                                                                                                                      \n",
    "                                                                                                                                                        \n",
    "# Parameter search space                                                                                                                                \n",
    "param_dist_xgb = {                                                                                                                                      \n",
    "    'model__n_estimators': [100, 200, 300, 400, 500],                                                                                                   \n",
    "    'model__learning_rate': [0.01, 0.03, 0.05, 0.1, 0.15],                                                                                              \n",
    "    'model__max_depth': [2, 3, 4, 5, 6],                                                                                                                \n",
    "    'model__min_child_weight': [1, 3, 5, 7],                                                                                                            \n",
    "    'model__subsample': [0.7, 0.8, 0.9, 1.0],                                                                                                           \n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9, 1.0],                                                                                                    \n",
    "    'model__reg_alpha': [0, 0.01, 0.1, 1],                                                                                                              \n",
    "    'model__reg_lambda': [0.1, 1, 5, 10]                                                                                                                \n",
    "}                                                                                                                                                       \n",
    "                                                                                                                                                        \n",
    "print(\"Tuning XGBoost...\")                                                                                                                              \n",
    "start = time.time()                                                                                                                                     \n",
    "                                                                                                                                                        \n",
    "search_xgb = RandomizedSearchCV(                                                                                                                        \n",
    "    pipe_xgb,                                                                                                                                           \n",
    "    param_distributions=param_dist_xgb,                                                                                                                 \n",
    "    n_iter=100,                                                                                                                                         \n",
    "    cv=cv,                                                                                                                                              \n",
    "    scoring='r2',                                                                                                                                       \n",
    "    n_jobs=-1,                                                                                                                                          \n",
    "    random_state=RANDOM,                                                                                                                                \n",
    "    verbose=1                                                                                                                                           \n",
    ")                                                                                                                                                       \n",
    "                                                                                                                                                        \n",
    "search_xgb.fit(X, y)                                                                                                                                    \n",
    "elapsed = time.time() - start                                                                                                                           \n",
    "                                                                                                                                                        \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                 \n",
    "print(f\"Best CV R²: {search_xgb.best_score_:.4f}\")                                                                                                      \n",
    "print(f\"\\nBest parameters:\")                                                                                                                            \n",
    "for param, value in search_xgb.best_params_.items():                                                                                                    \n",
    "    print(f\"  {param}: {value}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daa44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e4259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LightGBM...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "Completed in 132.8s\n",
      "Best CV R²: 0.4753\n",
      "\n",
      "Best parameters:\n",
      "  model__subsample: 0.8\n",
      "  model__reg_lambda: 0\n",
      "  model__reg_alpha: 0.01\n",
      "  model__num_leaves: 7\n",
      "  model__n_estimators: 300\n",
      "  model__min_child_samples: 20\n",
      "  model__max_depth: 5\n",
      "  model__learning_rate: 0.03\n",
      "  model__colsample_bytree: 0.8\n"
     ]
    }
   ],
   "source": [
    "pipe_lgb = Pipeline([                                                                                                                                        \n",
    "      ('prep', preprocessor),                                                                                                                                  \n",
    "      ('model', LGBMRegressor(random_state=RANDOM, n_jobs=-1, verbose=-1))                                                                                     \n",
    "  ])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "param_dist_lgb = {                                                                                                                                           \n",
    "    'model__n_estimators': [100, 200, 300, 400, 500],                                                                                                        \n",
    "    'model__learning_rate': [0.01, 0.03, 0.05, 0.1],                                                                                                         \n",
    "    'model__max_depth': [2, 3, 4, 5, -1],                                                                                                                    \n",
    "    'model__num_leaves': [7, 15, 31, 63],                                                                                                                    \n",
    "    'model__min_child_samples': [5, 10, 20, 30],                                                                                                             \n",
    "    'model__subsample': [0.7, 0.8, 0.9, 1.0],                                                                                                                \n",
    "    'model__colsample_bytree': [0.7, 0.8, 0.9, 1.0],                                                                                                         \n",
    "    'model__reg_alpha': [0, 0.01, 0.1, 1],                                                                                                                   \n",
    "    'model__reg_lambda': [0, 0.1, 1, 5]                                                                                                                      \n",
    "}                                                                                                                                                            \n",
    "                                                                                                                                                            \n",
    "print(\"Tuning LightGBM...\")                                                                                                                                  \n",
    "start = time.time()                                                                                                                                          \n",
    "                                                                                                                                                            \n",
    "search_lgb = RandomizedSearchCV(                                                                                                                             \n",
    "    pipe_lgb,                                                                                                                                                \n",
    "    param_distributions=param_dist_lgb,                                                                                                                      \n",
    "    n_iter=100,                                                                                                                                              \n",
    "    cv=cv,                                                                                                                                                   \n",
    "    scoring='r2',                                                                                                                                            \n",
    "    n_jobs=-1,                                                                                                                                               \n",
    "    random_state=RANDOM,                                                                                                                                     \n",
    "    verbose=1                                                                                                                                                \n",
    ")                                                                                                                                                            \n",
    "                                                                                                                                                            \n",
    "search_lgb.fit(X, y)                                                                                                                                         \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                      \n",
    "print(f\"Best CV R²: {search_lgb.best_score_:.4f}\")                                                                                                           \n",
    "print(f\"\\nBest parameters:\")                                                                                                                                 \n",
    "for param, value in search_lgb.best_params_.items():                                                                                                         \n",
    "    print(f\"  {param}: {value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de4c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7402973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_best = Pipeline([                                                                                                                                         \n",
    "    ('prep', preprocessor),                                                                                                                                  \n",
    "    ('model', GradientBoostingRegressor(                                                                                                                     \n",
    "        learning_rate=0.05, max_depth=2, n_estimators=300,                                                                                                   \n",
    "        min_samples_leaf=5, subsample=0.85, random_state=RANDOM                                                                                              \n",
    "    ))                                                                                                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "xgb_best = Pipeline([                                                                                                                                        \n",
    "    ('prep', preprocessor),                                                                                                                                  \n",
    "    ('model', XGBRegressor(                                                                                                                                  \n",
    "        learning_rate=0.03, max_depth=2, n_estimators=400,                                                                                                   \n",
    "        min_child_weight=1, subsample=0.7, colsample_bytree=0.7,                                                                                             \n",
    "        reg_alpha=1, reg_lambda=5, random_state=RANDOM, n_jobs=-1                                                                                            \n",
    "    ))                                                                                                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "lgb_best = Pipeline([                                                                                                                                        \n",
    "    ('prep', preprocessor),                                                                                                                                  \n",
    "    ('model', LGBMRegressor(                                                                                                                                 \n",
    "        learning_rate=0.03, max_depth=5, n_estimators=300,                                                                                                   \n",
    "        num_leaves=7, min_child_samples=20, subsample=0.8,                                                                                                   \n",
    "        colsample_bytree=0.8, reg_alpha=0.01, reg_lambda=0,                                                                                                  \n",
    "        random_state=RANDOM, n_jobs=-1, verbose=-1                                                                                                           \n",
    "    ))                                                                                                                                                       \n",
    "])                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f1d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingRegressor(                                                                                                                                   \n",
    "    estimators=[                                                                                                                                             \n",
    "        ('gb', gb_best),                                                                                                                                     \n",
    "        ('xgb', xgb_best),                                                                                                                                   \n",
    "        ('lgb', lgb_best)                                                                                                                                    \n",
    "    ],                                                                                                                                                       \n",
    "    final_estimator=Ridge(alpha=1.0),                                                                                                                        \n",
    "    cv=5,                                                                                                                                                    \n",
    "    n_jobs=-1                                                                                                                                                \n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "803912c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Stacking Ensemble...\n",
      "\n",
      "Completed in 39.8s\n",
      "Stacking CV R²: 0.4760 ± 0.0176\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Stacking Ensemble...\")                                                                                                                     \n",
    "start = time.time()                                                                                                                                          \n",
    "scores = cross_val_score(stack, X, y, cv=cv, scoring='r2', n_jobs=-1)                                                                                        \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                      \n",
    "print(f\"Stacking CV R²: {scores.mean():.4f} ± {scores.std():.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518788fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Stacking with RF...\n",
      "\n",
      "Completed in 276.6s\n",
      "Stacking+RF CV R²: 0.4758 ± 0.0176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor                                                                                                           \n",
    "                                                                                                                                                            \n",
    "rf_tuned = Pipeline([                                                                                                                                        \n",
    "    ('prep', preprocessor),                                                                                                                                  \n",
    "    ('model', RandomForestRegressor(                                                                                                                         \n",
    "        n_estimators=600, max_depth=None, min_samples_leaf=2,                                                                                                \n",
    "        random_state=RANDOM, n_jobs=-1                                                                                                                       \n",
    "    ))                                                                                                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "stack_with_rf = StackingRegressor(                                                                                                                           \n",
    "    estimators=[                                                                                                                                             \n",
    "        ('gb', gb_best),                                                                                                                                     \n",
    "        ('xgb', xgb_best),                                                                                                                                   \n",
    "        ('lgb', lgb_best),                                                                                                                                   \n",
    "        ('rf', rf_tuned)                                                                                                                                     \n",
    "    ],                                                                                                                                                       \n",
    "    final_estimator=Ridge(alpha=1.0),                                                                                                                        \n",
    "    cv=5,                                                                                                                                                    \n",
    "    n_jobs=-1                                                                                                                                                \n",
    ")                                                                                                                                                            \n",
    "                                                                                                                                                            \n",
    "print(\"Evaluating Stacking with RF...\")                                                                                                                      \n",
    "start = time.time()                                                                                                                                          \n",
    "scores = cross_val_score(stack_with_rf, X, y, cv=cv, scoring='r2', n_jobs=-1)                                                                                \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                      \n",
    "print(f\"Stacking+RF CV R²: {scores.mean():.4f} ± {scores.std():.4f}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09d675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6feff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e773d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions: 40 features\n",
      "Output dimensions: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "X_nn = nn_preprocessor.fit_transform(X)\n",
    "y_nn = y.values\n",
    "\n",
    "print(f\"Input dimensions: {X_nn.shape[1]} features\")\n",
    "print(f\"Output dimensions: {y_nn.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe7fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    batch_size=64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=RANDOM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e9f6a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP...\n",
      "\n",
      "Completed in 3.8s\n",
      "MLP CV R²: 0.3904 ± 0.0127\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating MLP...\")                                                                                                                                   \n",
    "start = time.time()                                                                                                                                          \n",
    "scores = cross_val_score(mlp, X_nn, y_nn, cv=cv, scoring='r2', n_jobs=-1)                                                                                    \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                      \n",
    "print(f\"MLP CV R²: {scores.mean():.4f} ± {scores.std():.4f}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4d2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 26\n",
      "Engineered features: 49\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'search_lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     28\u001b[39m preprocessor_eng = ColumnTransformer([                                                                                                                       \n\u001b[32m     29\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, OneHotEncoder(drop=\u001b[33m'\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m'\u001b[39m, sparse_output=\u001b[38;5;28;01mFalse\u001b[39;00m), cat_cols_eng),                                                                                 \n\u001b[32m     30\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m'\u001b[39m, num_cols_eng)                                                                                                                     \n\u001b[32m     31\u001b[39m ])                                                                                                                                                           \n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Test with LightGBM (fastest)                                                                                                                               \u001b[39;00m\n\u001b[32m     34\u001b[39m pipe_lgb_eng = Pipeline([                                                                                                                                    \n\u001b[32m     35\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preprocessor_eng),                                                                                                                              \n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, LGBMRegressor(**\u001b[43msearch_lgb\u001b[49m.best_params_, random_state=RANDOM, n_jobs=-\u001b[32m1\u001b[39m, verbose=-\u001b[32m1\u001b[39m))                                                          \n\u001b[32m     37\u001b[39m ])                                                                                                                                                           \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Remove 'model__' prefix from params                                                                                                                        \u001b[39;00m\n\u001b[32m     40\u001b[39m lgb_params = {k.replace(\u001b[33m'\u001b[39m\u001b[33mmodel__\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m search_lgb.best_params_.items()}                                                                       \n",
      "\u001b[31mNameError\u001b[39m: name 'search_lgb' is not defined"
     ]
    }
   ],
   "source": [
    "latent_uniform = ['a1', 'a2', 'a3', 'a4', 'a5', 'b1', 'b2', 'b3', 'b4', 'b5']                                                                                \n",
    "latent_gaussian = ['a6', 'a7', 'a8', 'a9', 'a10', 'b6', 'b7', 'b8', 'b9', 'b10']                                                                             \n",
    "                                                                                                                                                            \n",
    "# Create engineered features                                                                                                                                 \n",
    "X_eng = X.copy()                                                                                                                                             \n",
    "                                                                                                                                                            \n",
    "# 1. Interactions within latent groups (a*b pairs)                                                                                                           \n",
    "for i in range(1, 11):                                                                                                                                       \n",
    "    X_eng[f'ab_{i}'] = X[f'a{i}'] * X[f'b{i}']                                                                                                               \n",
    "                                                                                                                                                            \n",
    "# 2. Sum/mean aggregations                                                                                                                                   \n",
    "X_eng['a_sum'] = X[[f'a{i}' for i in range(1,11)]].sum(axis=1)                                                                                               \n",
    "X_eng['b_sum'] = X[[f'b{i}' for i in range(1,11)]].sum(axis=1)                                                                                               \n",
    "X_eng['ab_diff'] = X_eng['a_sum'] - X_eng['b_sum']                                                                                                           \n",
    "                                                                                                                                                            \n",
    "# 3. Gaussian latent squared terms (capture non-linearity)                                                                                                   \n",
    "for col in latent_gaussian:                                                                                                                                  \n",
    "    X_eng[f'{col}_sq'] = X[col] ** 2                                                                                                                         \n",
    "                                                                                                                                                            \n",
    "print(f\"Original features: {X.shape[1]}\")                                                                                                                    \n",
    "print(f\"Engineered features: {X_eng.shape[1]}\")                                                                                                              \n",
    "                                                                                                                                                            \n",
    "# Update column lists                                                                                                                                        \n",
    "cat_cols_eng = categorical_cols                                                                                                                                      \n",
    "num_cols_eng = [c for c in X_eng.columns if c not in categorical_cols]                                                                                               \n",
    "                                                                                                                                                            \n",
    "# New preprocessor                                                                                                                                           \n",
    "preprocessor_eng = ColumnTransformer([                                                                                                                       \n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols_eng),                                                                                 \n",
    "    ('num', 'passthrough', num_cols_eng)                                                                                                                     \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "# Test with LightGBM (fastest)                                                                                                                               \n",
    "pipe_lgb_eng = Pipeline([                                                                                                                                    \n",
    "    ('prep', preprocessor_eng),                                                                                                                              \n",
    "    ('model', LGBMRegressor(**search_lgb.best_params_, random_state=RANDOM, n_jobs=-1, verbose=-1))                                                          \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "# Remove 'model__' prefix from params                                                                                                                        \n",
    "lgb_params = {k.replace('model__', ''): v for k, v in search_lgb.best_params_.items()}                                                                       \n",
    "pipe_lgb_eng = Pipeline([                                                                                                                                    \n",
    "    ('prep', preprocessor_eng),                                                                                                                              \n",
    "    ('model', LGBMRegressor(**lgb_params, random_state=RANDOM, n_jobs=-1, verbose=-1))                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "print(\"\\nEvaluating LightGBM with engineered features...\")                                                                                                   \n",
    "start = time.time()                                                                                                                                          \n",
    "scores = cross_val_score(pipe_lgb_eng, X_eng, y, cv=cv, scoring='r2', n_jobs=-1)                                                                             \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"Completed in {elapsed:.1f}s\")                                                                                                                        \n",
    "print(f\"LightGBM + Engineered CV R²: {scores.mean():.4f} ± {scores.std():.4f}\")                                                                              \n",
    "print(f\"vs baseline LightGBM: 0.4753\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ed3f0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      2\u001b[39m gb_eng = Pipeline([                                                                                                                                          \n\u001b[32m      3\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preprocessor_eng),                                                                                                                              \n\u001b[32m      4\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, GradientBoostingRegressor(                                                                                                                     \n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     ))                                                                                                                                                       \n\u001b[32m      8\u001b[39m ])                                                                                                                                                           \n\u001b[32m     10\u001b[39m xgb_eng = Pipeline([                                                                                                                                         \n\u001b[32m     11\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preprocessor_eng),                                                                                                                              \n\u001b[32m     12\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, XGBRegressor(                                                                                                                                  \n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     ))                                                                                                                                                       \n\u001b[32m     17\u001b[39m ])                                                                                                                                                           \n\u001b[32m     19\u001b[39m lgb_eng = Pipeline([                                                                                                                                         \n\u001b[32m     20\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preprocessor_eng),                                                                                                                              \n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, LGBMRegressor(**\u001b[43mlgb_params\u001b[49m, random_state=RANDOM, n_jobs=-\u001b[32m1\u001b[39m, verbose=-\u001b[32m1\u001b[39m))                                                                       \n\u001b[32m     22\u001b[39m ])                                                                                                                                                           \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Stacking with engineered features                                                                                                                          \u001b[39;00m\n\u001b[32m     25\u001b[39m stack_eng = StackingRegressor(                                                                                                                               \n\u001b[32m     26\u001b[39m     estimators=[                                                                                                                                             \n\u001b[32m     27\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mgb\u001b[39m\u001b[33m'\u001b[39m, gb_eng),                                                                                                                                      \n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m                                                                                                                                                \n\u001b[32m     34\u001b[39m )                                                                                                                                                            \n",
      "\u001b[31mNameError\u001b[39m: name 'lgb_params' is not defined"
     ]
    }
   ],
   "source": [
    " # Update all pipelines with engineered features                                                                                                              \n",
    "gb_eng = Pipeline([                                                                                                                                          \n",
    "    ('prep', preprocessor_eng),                                                                                                                              \n",
    "    ('model', GradientBoostingRegressor(                                                                                                                     \n",
    "        learning_rate=0.05, max_depth=2, n_estimators=300,                                                                                                   \n",
    "        min_samples_leaf=5, subsample=0.85, random_state=RANDOM                                                                                              \n",
    "    ))                                                                                                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "xgb_eng = Pipeline([                                                                                                                                         \n",
    "    ('prep', preprocessor_eng),                                                                                                                              \n",
    "    ('model', XGBRegressor(                                                                                                                                  \n",
    "        learning_rate=0.03, max_depth=2, n_estimators=400,                                                                                                   \n",
    "        min_child_weight=1, subsample=0.7, colsample_bytree=0.7,                                                                                             \n",
    "        reg_alpha=1, reg_lambda=5, random_state=RANDOM, n_jobs=-1                                                                                            \n",
    "    ))                                                                                                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "lgb_eng = Pipeline([                                                                                                                                         \n",
    "    ('prep', preprocessor_eng),                                                                                                                              \n",
    "    ('model', LGBMRegressor(**lgb_params, random_state=RANDOM, n_jobs=-1, verbose=-1))                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "# Stacking with engineered features                                                                                                                          \n",
    "stack_eng = StackingRegressor(                                                                                                                               \n",
    "    estimators=[                                                                                                                                             \n",
    "        ('gb', gb_eng),                                                                                                                                      \n",
    "        ('xgb', xgb_eng),                                                                                                                                    \n",
    "        ('lgb', lgb_eng)                                                                                                                                     \n",
    "    ],                                                                                                                                                       \n",
    "    final_estimator=Ridge(alpha=1.0),                                                                                                                        \n",
    "    cv=5,                                                                                                                                                    \n",
    "    n_jobs=-1                                                                                                                                                \n",
    ")                                                                                                                                                            \n",
    "                                                                                                                                                            \n",
    "print(\"Evaluating Stacking with engineered features...\")                                                                                                     \n",
    "start = time.time()                                                                                                                                          \n",
    "scores = cross_val_score(stack_eng, X_eng, y, cv=cv, scoring='r2', n_jobs=-1)                                                                                \n",
    "elapsed = time.time() - start                                                                                                                                \n",
    "                                                                                                                                                            \n",
    "print(f\"\\nCompleted in {elapsed:.1f}s\")                                                                                                                      \n",
    "print(f\"Stacking + Engineered CV R²: {scores.mean():.4f} ± {scores.std():.4f}\")                                                                              \n",
    "print(f\"vs baseline Stacking: 0.4760\")                                                                                                                       \n",
    "print(f\"vs LightGBM + Engineered: 0.4788\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b3af91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 69\n",
      "Quick test with extended features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM + Extended: 0.4784 ± 0.0171\n"
     ]
    }
   ],
   "source": [
    "# Add a few more features                                                                                                                                    \n",
    "X_eng2 = X_eng.copy()                                                                                                                                        \n",
    "                                                                                                                                                            \n",
    "# Cross-group: uniform * gaussian interactions                                                                                                               \n",
    "for i in range(1, 6):                                                                                                                                        \n",
    "    X_eng2[f'a{i}_x_a{i+5}'] = X[f'a{i}'] * X[f'a{i+5}']                                                                                                     \n",
    "    X_eng2[f'b{i}_x_b{i+5}'] = X[f'b{i}'] * X[f'b{i+5}']                                                                                                     \n",
    "                                                                                                                                                            \n",
    "# Absolute values of gaussian (symmetric signal)                                                                                                             \n",
    "for col in latent_gaussian:                                                                                                                                  \n",
    "    X_eng2[f'{col}_abs'] = X[col].abs()                                                                                                                      \n",
    "                                                                                                                                                            \n",
    "print(f\"Features: {X_eng2.shape[1]}\")                                                                                                                        \n",
    "                                                                                                                                                            \n",
    "# Quick test with LightGBM                                                                                                                                   \n",
    "num_cols_eng2 = [c for c in X_eng2.columns if c not in categorical_cols]                                                                                             \n",
    "preprocessor_eng2 = ColumnTransformer([                                                                                                                      \n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols),                                                                                     \n",
    "    ('num', 'passthrough', num_cols_eng2)                                                                                                                    \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "pipe_test = Pipeline([                                                                                                                                       \n",
    "    ('prep', preprocessor_eng2),                                                                                                                             \n",
    "    ('model', LGBMRegressor(**lgb_params, random_state=RANDOM, n_jobs=-1, verbose=-1))                                                                       \n",
    "])                                                                                                                                                           \n",
    "                                                                                                                                                            \n",
    "print(\"Quick test with extended features...\")                                                                                                                \n",
    "scores = cross_val_score(pipe_test, X_eng2, y, cv=cv, scoring='r2', n_jobs=-1)                                                                               \n",
    "print(f\"LightGBM + Extended: {scores.mean():.4f} ± {scores.std():.4f}\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810fa10f",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Phase 7: Advanced Experiments\n",
    "# ============================================================\n",
    "# 1. CatBoost\n",
    "# 2. Feature Selection (Permutation Importance)\n",
    "# 3. Target Encoding\n",
    "# 4. Weighted Averaging vs Stacking\n",
    "# 5. Learning Curve & Residual Analysis\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ofj5bdjewqs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: CatBoost - SKIPPED\n",
    "# CatBoost fails to build on Clang 20 / Python 3.14 (Conan compiler version not supported)\n",
    "# Moving on to remaining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08lngg0c1t2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_lgb_eng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Train LightGBM on full data to get importance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpipe_lgb_eng\u001b[49m.fit(X_eng, y)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Permutation importance (slower but more reliable than built-in)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComputing permutation importance...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipe_lgb_eng' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Experiment 2: Feature Selection (Permutation Importance) ---\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Train LightGBM on full data to get importance\n",
    "pipe_lgb_eng.fit(X_eng, y)\n",
    "\n",
    "# Permutation importance (slower but more reliable than built-in)\n",
    "print(\"Computing permutation importance...\")\n",
    "start = time.time()\n",
    "perm_result = permutation_importance(\n",
    "    pipe_lgb_eng, X_eng, y, \n",
    "    n_repeats=10, random_state=RANDOM, scoring='r2', n_jobs=-1\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Completed in {elapsed:.1f}s\")\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "cat_feature_names = pipe_lgb_eng.named_steps['prep'].transformers_[0][1].get_feature_names_out(categorical_cols).tolist()\n",
    "all_feature_names = cat_feature_names + num_cols_eng\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance_mean': perm_result.importances_mean,\n",
    "    'importance_std': perm_result.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features:\")\n",
    "print(importance_df.head(20).to_string(index=False))\n",
    "print(f\"\\nFeatures with negative importance (noise):\")\n",
    "noise_features = importance_df[importance_df['importance_mean'] <= 0]\n",
    "print(f\"  {len(noise_features)} features contribute nothing or hurt performance\")\n",
    "print(noise_features['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zlho58eidx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 3: Target Encoding ---\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "preprocessor_te = ColumnTransformer([\n",
    "    ('cat', TargetEncoder(random_state=RANDOM), categorical_cols),\n",
    "    ('num', 'passthrough', num_cols_eng)\n",
    "])\n",
    "\n",
    "pipe_lgb_te = Pipeline([\n",
    "    ('prep', preprocessor_te),\n",
    "    ('model', LGBMRegressor(**lgb_params, random_state=RANDOM, n_jobs=-1, verbose=-1))\n",
    "])\n",
    "\n",
    "print(\"Evaluating LightGBM with Target Encoding...\")\n",
    "start = time.time()\n",
    "scores_te = cross_val_score(pipe_lgb_te, X_eng, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Completed in {elapsed:.1f}s\")\n",
    "print(f\"LightGBM + Target Encoding CV R²: {scores_te.mean():.4f} ± {scores_te.std():.4f}\")\n",
    "print(f\"vs LightGBM + OneHot:             0.4788\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pbc9qnkq0q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 4: Weighted Averaging ---\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Get out-of-fold predictions from each model\n",
    "print(\"Getting out-of-fold predictions...\")\n",
    "start = time.time()\n",
    "\n",
    "pred_gb = cross_val_predict(gb_eng, X_eng, y, cv=cv, n_jobs=-1)\n",
    "pred_xgb = cross_val_predict(xgb_eng, X_eng, y, cv=cv, n_jobs=-1)\n",
    "pred_lgb = cross_val_predict(lgb_eng, X_eng, y, cv=cv, n_jobs=-1)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Completed in {elapsed:.1f}s\")\n",
    "\n",
    "# Test different weight combinations\n",
    "best_r2 = 0\n",
    "best_weights = None\n",
    "\n",
    "for w1 in np.arange(0.1, 0.8, 0.05):\n",
    "    for w2 in np.arange(0.1, 0.8, 0.05):\n",
    "        w3 = 1 - w1 - w2\n",
    "        if w3 < 0.05:\n",
    "            continue\n",
    "        blend = w1 * pred_gb + w2 * pred_xgb + w3 * pred_lgb\n",
    "        r2 = r2_score(y, blend)\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_weights = (w1, w2, w3)\n",
    "\n",
    "print(f\"\\nBest weighted average R²: {best_r2:.4f}\")\n",
    "print(f\"Weights: GB={best_weights[0]:.2f}, XGB={best_weights[1]:.2f}, LGB={best_weights[2]:.2f}\")\n",
    "print(f\"vs Stacking (Ridge meta): 0.4807\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dosda88sj3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment 5: Learning Curve & Residual Analysis ---\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Computing learning curve (this may take a few minutes)...\")\n",
    "start = time.time()\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    lgb_eng, X_eng, y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=cv, scoring='r2', n_jobs=-1\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Completed in {elapsed:.1f}s\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Learning Curve\n",
    "ax = axes[0]\n",
    "ax.plot(train_sizes, train_scores.mean(axis=1), 'o-', label='Train R²')\n",
    "ax.plot(train_sizes, val_scores.mean(axis=1), 'o-', label='Validation R²')\n",
    "ax.fill_between(train_sizes,\n",
    "                val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                val_scores.mean(axis=1) + val_scores.std(axis=1), alpha=0.2)\n",
    "ax.set_xlabel('Training Set Size')\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('Learning Curve (LightGBM)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residual Analysis\n",
    "pred_oof = cross_val_predict(lgb_eng, X_eng, y, cv=cv, n_jobs=-1)\n",
    "residuals = y - pred_oof\n",
    "\n",
    "ax = axes[1]\n",
    "ax.scatter(pred_oof, residuals, alpha=0.15, s=5)\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title(f'Residuals (OOF R² = {r2_score(y, pred_oof):.4f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Diagnose: is the gap closing?\n",
    "print(f\"\\nTrain R² at full data:      {train_scores.mean(axis=1)[-1]:.4f}\")\n",
    "print(f\"Validation R² at full data: {val_scores.mean(axis=1)[-1]:.4f}\")\n",
    "gap = train_scores.mean(axis=1)[-1] - val_scores.mean(axis=1)[-1]\n",
    "print(f\"Gap: {gap:.4f}\")\n",
    "if gap > 0.15:\n",
    "    print(\"-> Large gap: model is overfitting. More regularization or data could help.\")\n",
    "elif val_scores.mean(axis=1)[-1] - val_scores.mean(axis=1)[-3] < 0.005:\n",
    "    print(\"-> Validation curve is flat: approaching irreducible noise ceiling.\")\n",
    "else:\n",
    "    print(\"-> Validation still improving: more data would likely help.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
